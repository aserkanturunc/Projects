{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRxLZgiY5mc2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuiSzEY9caph"
      },
      "source": [
        "$$\\text{IEOR 142 Final Project - Battling COVID-19 Falsehoods with Machine Learning Approaches\n",
        "}$$\n",
        "$$\\text{Ahmet Turunc, Catherine Lei, Pranav Viswanathan, Vishnu Karukonda, Wako Morimoto\n",
        "}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_tvIDdcdOGt"
      },
      "source": [
        "Data Sources \n",
        "\n",
        "Tweet and text data: https://github.com/MickeysClubhouse/COVID-19-rumor-dataset\n",
        "\n",
        "COVID case and vaccination data by country: https://github.com/owid/covid-19-data/tree/master/public/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AanrZmjL76CX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/IEOR 142 Final Project\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jROVFaTT5-Mz"
      },
      "source": [
        "## Read in data\n",
        "text_data: tweets and news articles with some additional values\n",
        "\n",
        "case_data: COVID case data from OWID resource"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CE6p54kU57AV"
      },
      "outputs": [],
      "source": [
        "text_data = pd.read_csv('en_dup.csv')\n",
        "case_data = pd.read_csv('owid-covid-data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRNJYUx1-hrM"
      },
      "source": [
        "## Filtering data that has T/F labels, and a date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAFzfBvd-lFW"
      },
      "outputs": [],
      "source": [
        "filter_data = text_data[text_data['label'].isnull()==False]\n",
        "filter_data = filter_data[filter_data[\"label\"] != \"U\"]\n",
        "filter_data = filter_data[filter_data['time'].isnull()==False]\n",
        "filter_data.index = np.arange(1, len(filter_data) + 1)\n",
        "filter_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwDeeaCw-7dq"
      },
      "source": [
        "[\"time\"]  columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQmYoOC1--QS"
      },
      "source": [
        "###As seen below, time is stored in multiple different formats. We want time to match our \"Case_data\" dataset, so we want to reformat time to a yyyy-mm-dd format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HMfES9q-lgM"
      },
      "outputs": [],
      "source": [
        "filter_data[\"time\"].tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2n8CSikc_AhI"
      },
      "outputs": [],
      "source": [
        "def time_fixer(df):\n",
        "  df = df.copy()\n",
        "\n",
        "  #Making all yyyy/mm/dd into yyyy-mm-dd\n",
        "  x = df[\"time\"].str.replace(\"/\",\"-\")\n",
        "\n",
        "  #Splitting into columns accesible by RangeIndex\n",
        "  y = x.str.split(expand = True)\n",
        "  y = y.fillna(value = 0)\n",
        "\n",
        "  #Column 4 - Removing commas at the end of days + Replacing values in other formats with 0\n",
        "  y[4] = y[4].replace(\"+0000\", 0)\n",
        "  y[4] = y[4].str.replace(',','')\n",
        "\n",
        "  #Columns 3 - Remapping months, and removing values with :\n",
        "  y[3] = np.where(y[3].str.contains(\":\", na=False), 0, y[3])\n",
        "    #These are the only month values in y[4]\n",
        "  m2d = {\"Jan\": \"01\", \"Feb\": \"02\", \"Mar\": \"03\", \"Oct\": \"10\"}\n",
        "  y[3] = y[3].map(m2d)  \n",
        "\n",
        "  #Column 0 - Removing values without - \n",
        "  y[0] = np.where(~y[0].str.contains(\"-\", na=False), 0, y[0])\n",
        "\n",
        "  #Column 1 - Remapping months, Replacing AM/PM with NaN\n",
        "  m2d2 = {\"Jan\": \"01\", \"Feb\": \"02\", \"Mar\": \"03\", \"Oct\": \"10\"}\n",
        "  y[1] = y[1].map(m2d2)\n",
        "\n",
        "  #creating a list of nans or those already in the correct format\n",
        "  y_arr = np.array(y[0])\n",
        "  y_arr\n",
        "\n",
        "\n",
        "  #creating a list that has the correct format for things in the AM/PM ... format and nans for all other values\n",
        "\n",
        "  join_list = np.array([])\n",
        "  for i in range(1,1776):\n",
        "    if y[5][i] != 0:\n",
        "      if pd.isnull(y[4][i]) == False:\n",
        "        if pd.isnull(y[3][i]) == False:\n",
        "          format = y[5][i] + \"-\" + y[3][i] + \"-\" + y[4][i]\n",
        "          join_list = np.append(join_list, format)\n",
        "    if len(join_list) != i:\n",
        "      join_list = np.append(join_list, \"none\")\n",
        "\n",
        "  #creating a list that has the correct format for the final format\n",
        "\n",
        "  join_list_2 = np.array([])\n",
        "  for i in range(1,1776):\n",
        "    if y[5][i] != 0:\n",
        "      if pd.isnull(y[1][i]) == False:\n",
        "        if pd.isnull(y[2][i]) == False:\n",
        "          format = y[5][i] + \"-\" + y[1][i] + \"-\" + y[2][i]\n",
        "          join_list_2 = np.append(join_list_2, format)\n",
        "    if len(join_list_2) != i:\n",
        "      join_list_2 = np.append(join_list_2, \"none\")\n",
        "\n",
        "  #making all lists have the same \"null values\"\n",
        "  y_arr = y_arr.astype(str)\n",
        "  y_arr = np.where(y_arr ==\"0\", \"none\", y_arr)\n",
        "  y_arr\n",
        "\n",
        "  #merging the three lists to make a final list of the correct formats\n",
        "  full_list = np.array([])\n",
        "  for i in range(1775):\n",
        "    if y_arr[i] != \"none\":\n",
        "      full_list = np.append(full_list, y_arr[i] )\n",
        "    elif join_list[i] != \"none\":\n",
        "      full_list = np.append(full_list, join_list[i] )\n",
        "    elif join_list_2[i] != \"none\":\n",
        "      full_list = np.append(full_list, join_list_2[i] )\n",
        "    else:\n",
        "      full_list = np.append(full_list, \"none\")\n",
        "\n",
        "  #Some we want month values to be 0x instead of x (03 instead of 3) -- same thing for days.\n",
        "  final_list = np.array([])\n",
        "  for i in full_list:\n",
        "    if i != \"none\":\n",
        "      z = i.split(\"-\")\n",
        "    if len(z[1]) == 1:\n",
        "      z[1] = '0' + z[1]\n",
        "    if len(z[2]) == 1:\n",
        "      z[2] = '0' + z[2]\n",
        "    combined = z[0] + \"-\" + z[1] + \"-\" + z[2]\n",
        "    final_list = np.append(final_list, combined)\n",
        "  return final_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzff3ptHRZZz"
      },
      "outputs": [],
      "source": [
        "time_reform = time_fixer(filter_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNSX8pPKRe84"
      },
      "outputs": [],
      "source": [
        "#Do we have any \"none\" values? Nope!\n",
        "time_reform[time_reform == \"none\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng35Bv4FTJch"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Looking through y, we have 2 wierd data entries:\n",
        "\n",
        "'2020·Sprinklr-03-03'\n",
        "'202-01-22'\n",
        "\n",
        "'''\n",
        "np.where(time_reform == '2020·Sprinklr-03-03'), np.where(time_reform == '202-01-22')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rISx_fmCTK7N"
      },
      "outputs": [],
      "source": [
        "filter_data.iloc[547], filter_data.iloc[887]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ix3Nll7-TMGo"
      },
      "outputs": [],
      "source": [
        "time_reform = np.where(time_reform == '2020·Sprinklr-03-03', \"2020-03-03\", time_reform)\n",
        "#https://twitter.com/PMBreakingNews/status/1219687852486942721 found tweet to verify date\n",
        "time_reform = np.where(time_reform == '202-01-22', \"2020-01-22\", time_reform)\n",
        "filter_data[\"time\"] = time_reform\n",
        "filter_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYQekYxzpFV0"
      },
      "source": [
        "## NLP Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSqiuLrwtJcD"
      },
      "outputs": [],
      "source": [
        "#FUNCTIONS FROM LABS\n",
        "from string import punctuation\n",
        "\n",
        "def remove_punctuation(document):\n",
        "\n",
        "    punct2 = punctuation.replace('#','')\n",
        "    no_punct = ''.join([character for character in document if character not in punct2])\n",
        "    \n",
        "    return no_punct\n",
        "\n",
        "def remove_digit(document): \n",
        "    \n",
        "    no_digit = ''.join([character for character in document if not character.isdigit()])\n",
        "              \n",
        "    return no_digit\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(document):\n",
        "    \n",
        "    words = [word for word in document if not word in stop_words]\n",
        "    \n",
        "    return words\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "\n",
        "def stemmer(document):\n",
        "    \n",
        "    stemmed_document = [porter.stem(word) for word in document]\n",
        "    \n",
        "    return stemmed_document\n",
        "\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1XAl4UxpKoN"
      },
      "outputs": [],
      "source": [
        "#inspect raw data\n",
        "{print(x) for x in filter_data.head()['content']}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgPZHLsipbYj"
      },
      "source": [
        "Proposed text cleaning steps: remove t.co links, remove twitter @ mentions, COVID mentions, followed by typical NLP steps from lecture \n",
        "\n",
        "Typical NLP cleaning steps\n",
        "\n",
        "1) convert all chars to lowercase\n",
        "\n",
        "2) remove all punctuation\n",
        "\n",
        "3) remove any numeric values\n",
        "\n",
        "4) tokenize text entries\n",
        "\n",
        "5) remove stopwords from tokenized text\n",
        "\n",
        "6) Stem all words\n",
        "\n",
        "7) Detokenize text and use countvectorizer to create document-term matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58qggIhapo31"
      },
      "outputs": [],
      "source": [
        "#Convert to lowercase, remove t.co media links and remove all twitter @ mentions\n",
        "pre_cleaned_text = filter_data['content'].str.lower().str.replace('@[^ .]+', '',regex=True).str.replace('https://t.co/[A-Za-z0-9]+', '',regex=True)\n",
        "{print(x) for x in pre_cleaned_text.head()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZuZBuF3shex"
      },
      "outputs": [],
      "source": [
        "#Typical steps as performed in lab 8b and the NLP HW\n",
        "punctless = pre_cleaned_text.apply(remove_punctuation)\n",
        "digitless = punctless.apply(remove_digit)\n",
        "tokens = digitless.apply(word_tokenize)\n",
        "stopless = tokens.apply(remove_stopwords)\n",
        "only_stems = stopless.apply(stemmer)\n",
        "concat_text = only_stems.apply(TreebankWordDetokenizer().detokenize)\n",
        "ct_vec = CountVectorizer(min_df=0.01) #ARBITRARILY CHOSEN MIN_DF; COME BACK TO DECIDE ON A VALUE\n",
        "sparse = ct_vec.fit_transform(concat_text)\n",
        "text_features = pd.DataFrame(sparse.toarray(), columns=ct_vec.get_feature_names(), index=pre_cleaned_text.index)\n",
        "text_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfuOWzZwvMWQ"
      },
      "outputs": [],
      "source": [
        "#Create merged table with labels, date, and text_features\n",
        "text_final = text_features.copy()\n",
        "text_final['label'] = filter_data['label']\n",
        "text_final['date']= filter_data['time']\n",
        "text_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcMJ_nEl-Npc"
      },
      "outputs": [],
      "source": [
        "text_final['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAQnV6BKe8zL"
      },
      "source": [
        "##Filtering covid data set to get per capita features from different income groups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx14pihlfO4u"
      },
      "source": [
        "The case data groups several countries into income categories and contains covid statistics across those groups of countries; for the sake of convenience, these entries can be used from every date. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Edpl4HyfxSq"
      },
      "outputs": [],
      "source": [
        "#PREVIEWING CASE DATA\n",
        "case_data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OQIztjjod8g"
      },
      "outputs": [],
      "source": [
        "#Getting all US features\n",
        "US_cases = case_data[case_data['location'] == 'United States']\n",
        "\n",
        "#features that maybe do not add much value (daily cumulative counts primarily)\n",
        "features_to_drop = ['total_cases','total_cases_per_million','total_deaths_per_million','total_tests','total_tests_per_thousand','total_vaccinations','people_vaccinated','total_boosters',\n",
        "                    'total_vaccinations_per_hundred','total_boosters_per_hundred','population_density','median_age','aged_65_older','aged_70_older','gdp_per_capita','extreme_poverty',\n",
        "                    'cardiovasc_death_rate','diabetes_prevalence','female_smokers','male_smokers','handwashing_facilities','hospital_beds_per_thousand','life_expectancy','human_development_index',\n",
        "                    'excess_mortality_cumulative_absolute','excess_mortality_cumulative','excess_mortality','excess_mortality_cumulative_per_million','stringency_index','population', 'tests_units']\n",
        "filtered_US_features = US_cases.drop(features_to_drop, axis=1).drop(['iso_code', 'continent', 'location'],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxI_JTJwgOH6"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2dwkN4vvxhx"
      },
      "source": [
        "##Merge covid case data with text feature data set based on date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVY0ai4-v15-"
      },
      "outputs": [],
      "source": [
        "text_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kC-wIIYv35l"
      },
      "outputs": [],
      "source": [
        "filtered_US_features.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIuBKzplv5uJ"
      },
      "outputs": [],
      "source": [
        "combined_data = text_final.merge(filtered_US_features, how = 'left', left_on = 'date', right_on = 'date').drop(['date', 'date'], axis = 1)\n",
        "combined_data.tail()\n",
        "\n",
        "#combined_data = combined_data.replace(0.000, np.nan)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSypmmXTOIok"
      },
      "source": [
        "#### We notice that between each column and its \"smoothed\" version, values of NaN are represented as 0. This is an issue, as seen when looking ath the new_deaths and new_deaths_smoothed column. Having 0 deaths over a 7 day period is far different from having an unreported amount of deaths for 7 consecutive days. We will use the smooth features... (explain after discussing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ubzq4Z_kNwur"
      },
      "outputs": [],
      "source": [
        "#Dropping features that have a smooth column or a per_million/per thousand/per hundred col\n",
        "filtered_US_features_smooth = filtered_US_features.drop(['new_cases','new_cases_smoothed','new_deaths', \n",
        "                                                         'new_cases_per_million','new_deaths_per_million',\n",
        "                                                         'icu_patients','hosp_patients','weekly_icu_admissions',\n",
        "                                                         'weekly_hosp_admissions','new_tests','new_tests_per_thousand',\n",
        "                                                         'new_tests_smoothed','new_vaccinations','new_vaccinations_smoothed', 'new_people_vaccinated_smoothed'],axis=1)\n",
        "filtered_US_features_smooth\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWisEy_eN6Wl"
      },
      "outputs": [],
      "source": [
        "#combined_data_smooth = text_final.merge(filtered_US_features, how = 'left', left_on = 'date', right_on = 'date').drop(['date', 'date'], axis = 1)\n",
        "#combined_data_smooth = combined_data_smooth.replace(0.000,np.nan)\n",
        "#combined_data_smooth = combined_data_smooth.fillna(0) Slightly raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-_Iv1rYG2pQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "#IMPUTE IN MEAN VALUE FOR MISSING VAL\n",
        "imputer = SimpleImputer()\n",
        "imputed_data = imputer.fit_transform(combined_data.drop(['label'], axis=1))\n",
        "#imputed_data = imputer.fit_transform(combined_data_smooth.drop(['label'], axis=1))\n",
        "labels = combined_data['label'].str.replace('T','1').str.replace('F','0').astype(int)\n",
        "#labels = combined_data_smooth['label'].str.replace('T','1').str.replace('F','0').astype(int)\n",
        "imputed_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPf2-vYeiBZ5"
      },
      "source": [
        "**Readibility Scoring Tweets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bb3XdEmiHrM"
      },
      "source": [
        "We want to see if there is a difference in the readibility level of text between True and False tweets. However, most common readibility scores, such as the use Flesch and Gunning-fog use sentence related features in their analysis. Since tweets, unlike news articles or headlines have no expectation of being written well, it may be hard to identify sentences. Hence, we will use the smog formula.\n",
        "\n",
        "SMOG grading = 3 + √(polysyllable count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BERMp_59jCjX"
      },
      "outputs": [],
      "source": [
        "pip install https://github.com/andreasvc/readability/tarball/master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ck2CGckZy9Pf"
      },
      "outputs": [],
      "source": [
        "import readability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgSGRLeWjCmk"
      },
      "outputs": [],
      "source": [
        "all_grades = (filter_data[\"content\"]).apply(readability.getmeasures)\n",
        "T_grades = (filter_data[filter_data[\"label\"] == \"T\"][\"content\"]).apply(readability.getmeasures)\n",
        "F_grades = (filter_data[filter_data[\"label\"] == \"F\"][\"content\"]).apply(readability.getmeasures)\n",
        "all_grades.items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iedIQ7nMlkqj"
      },
      "outputs": [],
      "source": [
        "#To change the read_ratings, ['DaleChallIndex'] with a value in here https://pypi.org/project/readability/\n",
        "read_ratings = [i['readability grades']['DaleChallIndex'] for i in all_grades]\n",
        "T_read_ratings = [i['readability grades']['DaleChallIndex'] for i in T_grades]\n",
        "F_read_ratings = [i['readability grades']['DaleChallIndex'] for i in F_grades]\n",
        "read_ratings[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99BWjn98lAVF"
      },
      "outputs": [],
      "source": [
        "[np.mean(T_read_ratings),np.std(T_read_ratings)], [np.mean(F_read_ratings),np.std(F_read_ratings)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "x = sns.distplot(T_read_ratings, label='T r u e')\n",
        "sns.distplot(F_read_ratings, label='F a l s e')\n",
        "plt.legend()\n",
        "x.set_xlabel(\"Dale-Chall Score\", fontsize = 10)"
      ],
      "metadata": {
        "id": "KhDqh-8eqL8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8CI0b-Bl4Pa"
      },
      "source": [
        "Both True and False tweets have a similar score. Both scores, according to the SMOG index conversion table represent that the average covid-related tweet, regardless of True or False label, needs only a 6th grade reading level needed to fully understand. \n",
        "\n",
        "https://readabilityformulas.com/smog-readability-formula.php"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfWO8HIxlAXp"
      },
      "outputs": [],
      "source": [
        "combined_data[\"Readability\"] = read_ratings\n",
        "combined_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kqs8kDzcq8Ka"
      },
      "source": [
        "**Imputed Missing Data with Feature Means; Convert T/F labels to 1/0 respectively**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGlRhT04q5-v"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "#IMPUTE IN MEAN VALUE FOR MISSING VAL\n",
        "imputer = SimpleImputer()\n",
        "imputed_data = imputer.fit_transform(combined_data.drop(['label'], axis=1))\n",
        "#imputed_data = imputer.fit_transform(combined_data_smooth.drop(['label'], axis=1))\n",
        "labels = combined_data['label'].str.replace('T','1').str.replace('F','0').astype(int)\n",
        "#labels = combined_data_smooth['label'].str.replace('T','1').str.replace('F','0').astype(int)\n",
        "imputed_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxcjopWdxDUl"
      },
      "source": [
        "##Preliminary modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFkFRBpvxE7X"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, make_scorer, roc_auc_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "so4-CXh95YbY"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(y_true, y_pred):\n",
        "  cmtx = confusion_matrix(y_true, y_pred)\n",
        "  tn, fn, tp, fp = cmtx[0][0],cmtx[1][0],cmtx[1][1],cmtx[0][1]\n",
        "  metrics = {}\n",
        "  metrics['tpr'] = tp / (tp + fn)\n",
        "  metrics['fpr'] = fp / (fp + tn)\n",
        "  metrics['accuracy'] = np.mean(y_true==y_pred)\n",
        "  return metrics\n",
        "\n",
        "#Code from lab 4 (adapted)\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "def plot_roc(y_test, predict_probas, model_names):\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plt.title('ROC Curve', fontsize=18)\n",
        "  plt.xlabel('FPR', fontsize=16)\n",
        "  plt.ylabel('TPR', fontsize=16)\n",
        "  plt.xlim([-0.01, 1.00])\n",
        "  plt.ylim([-0.01, 1.01])\n",
        "  for i,y_proba in enumerate(predict_probas):\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=3, label=model_names[i]+' (area = {:0.2f})'.format(roc_auc))\n",
        "  plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--', label='Naive Baseline (area = 0.50)')\n",
        "  plt.legend(loc='lower right', fontsize=14)\n",
        "  #plt.show()\n",
        "\n",
        "#Adapted from Lab 8b\n",
        "def bootstrap_validation(test_data, test_label, model, metrics_list, sample=5000, random_state=66):\n",
        "    n_sample = sample\n",
        "    n_metrics = len(metrics_list)\n",
        "    output_array=np.zeros([n_sample, n_metrics])\n",
        "    output_array[:]=np.nan\n",
        "    print(output_array.shape)\n",
        "    for bs_iter in range(n_sample):\n",
        "        bs_index = np.random.choice(test_data.index, len(test_data.index), replace=True)\n",
        "        bs_data = test_data.loc[bs_index]\n",
        "        bs_label = test_label.loc[bs_index]\n",
        "        bs_predicted = model.predict(bs_data)\n",
        "        bs_proba = model.predict_proba(bs_data)[:,1]\n",
        "        for metrics_iter in range(n_metrics):\n",
        "            metrics = metrics_list[metrics_iter]\n",
        "            output_array[bs_iter, metrics_iter]=metrics(bs_label,bs_predicted,bs_proba)\n",
        "    output_df = pd.DataFrame(output_array)\n",
        "    return output_df\n",
        "\n",
        "#custom written metric functions\n",
        "def get_tpr(y_true, y_pred,y_proba):\n",
        "  cmtx = confusion_matrix(y_true, y_pred)\n",
        "  tn, fn, tp, fp = cmtx[0][0],cmtx[1][0],cmtx[1][1],cmtx[0][1]\n",
        "  return tp / (tp + fn)\n",
        "def get_fpr(y_true, y_pred,y_proba):\n",
        "  cmtx = confusion_matrix(y_true, y_pred)\n",
        "  tn, fn, tp, fp = cmtx[0][0],cmtx[1][0],cmtx[1][1],cmtx[0][1]\n",
        "  return fp / (fp + tn)\n",
        "def get_accuracy(y_true, y_pred,y_proba):\n",
        "  return np.mean(y_true==y_pred)\n",
        "def get_AUC(y_true, y_pred,y_proba):\n",
        "  return roc_auc_score(y_true, y_proba)\n",
        "\n",
        "  #FOR CROSS VAL\n",
        "def cv_fpr(y_true, y_pred):\n",
        "  cmtx = confusion_matrix(y_true, y_pred)\n",
        "  tn, fn, tp, fp = cmtx[0][0],cmtx[1][0],cmtx[1][1],cmtx[0][1]\n",
        "  return fp / (fp + tn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejdQ4srL3ZzC"
      },
      "outputs": [],
      "source": [
        "#Construct 80/20 train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(imputed_data, labels, test_size=0.2, random_state=142)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te2xxdCT3gOh"
      },
      "source": [
        "###RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvLG3p6BxHYD"
      },
      "outputs": [],
      "source": [
        "rfc = RandomForestClassifier(random_state=142)\n",
        "parameters = {'max_features': np.arange(20,200,10)} #cv with ccp_alpha? \n",
        "cv = KFold(n_splits=5, random_state=142, shuffle=True) \n",
        "rfc = GridSearchCV(rfc, param_grid=parameters, scoring=make_scorer(cv_fpr, greater_is_better = False), cv=cv, verbose=0)\n",
        "rfc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyNNY-SzxdD4"
      },
      "outputs": [],
      "source": [
        "rfc_predict_proba = rfc.predict_proba(X_test)[:,1]\n",
        "rfc_predictions = rfc.predict(X_test)\n",
        "rfc.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXkj6zJhydFU"
      },
      "outputs": [],
      "source": [
        "#Code from lab 4\n",
        "plot_roc(y_test, [rfc_predict_proba], ['rfc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVFU_pjR30Nl"
      },
      "outputs": [],
      "source": [
        "rfc_performance = calculate_metrics(y_test, rfc_predictions)\n",
        "print({f\"{x}: {str(rfc_performance[x])}\" for x in rfc_performance})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvtT4WGa69B2"
      },
      "source": [
        "###Logistic Regression (regular, LASSO, Ridge, Elastic Net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nZA-1nK6-aa"
      },
      "outputs": [],
      "source": [
        "logistic_regression = LogisticRegression(random_state = 142, penalty = 'none', max_iter = 1000)\n",
        "logistic_regression.fit(X_train, y_train)\n",
        "\n",
        "lasso = LogisticRegression(random_state = 142, penalty = 'l1', solver = 'liblinear', max_iter = 1000)\n",
        "lasso.fit(X_train, y_train)\n",
        "\n",
        "ridge = LogisticRegression(random_state = 142, penalty = 'l2', solver = 'liblinear', max_iter = 1000)\n",
        "ridge.fit(X_train, y_train)\n",
        "\n",
        "#Elastic net: 50/50 mix of Lasso and Ridge regularization\n",
        "elastic_net = LogisticRegression(random_state = 142, solver = 'saga', penalty = 'elasticnet', l1_ratio = 0.5, max_iter = 1000)\n",
        "elastic_net.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZEsY3zu7E4J"
      },
      "outputs": [],
      "source": [
        "logreg_predict_proba = logistic_regression.predict_proba(X_test)[:,1]\n",
        "logreg_predictions = logistic_regression.predict(X_test)\n",
        "elastic_net_predict_proba = elastic_net.predict_proba(X_test)[:,1]\n",
        "elastic_net_predictions = elastic_net.predict(X_test)\n",
        "lasso_predict_proba = lasso.predict_proba(X_test)[:,1]\n",
        "lasso_predictions = lasso.predict(X_test)\n",
        "ridge_predict_proba = ridge.predict_proba(X_test)[:,1]\n",
        "ridge_predictions = ridge.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SOwrNzw7GXp"
      },
      "outputs": [],
      "source": [
        "logreg_performance = calculate_metrics(y_test, logreg_predictions)\n",
        "print({f\"{x}: {str(logreg_performance[x])}\" for x in logreg_performance})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceZQZWFf1UGQ"
      },
      "outputs": [],
      "source": [
        "elastic_net_performance = calculate_metrics(y_test, elastic_net_predictions)\n",
        "print({f\"{x}: {str(elastic_net_performance[x])}\" for x in elastic_net_performance})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTOBFOZR1UO6"
      },
      "outputs": [],
      "source": [
        "lasso_performance = calculate_metrics(y_test, lasso_predictions)\n",
        "print({f\"{x}: {str(lasso_performance[x])}\" for x in lasso_performance})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yEYZz721UZc"
      },
      "outputs": [],
      "source": [
        "ridge_performance = calculate_metrics(y_test, ridge_predictions)\n",
        "print({f\"{x}: {str(ridge_performance[x])}\" for x in ridge_performance})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev6rnjPR7cmK"
      },
      "source": [
        "###LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kk3A6jDA7eMb"
      },
      "outputs": [],
      "source": [
        "LDA = LinearDiscriminantAnalysis()\n",
        "LDA.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hKETjqb7eMb"
      },
      "outputs": [],
      "source": [
        "LDA_predict_proba = LDA.predict_proba(X_test)[:,1]\n",
        "LDA_predictions = LDA.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BzdmZF07eMb"
      },
      "outputs": [],
      "source": [
        "plot_roc(y_test, [LDA_predict_proba], ['LDA'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Izm7vTMr7eMb"
      },
      "outputs": [],
      "source": [
        "lda_performance = calculate_metrics(y_test, LDA_predictions)\n",
        "print({f\"{x}: {str(lda_performance[x])}\" for x in lda_performance})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qniLAIMg3Bsa"
      },
      "source": [
        "###GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnfdswRO3F-h"
      },
      "outputs": [],
      "source": [
        "gbc = GradientBoostingClassifier(random_state=142)\n",
        "parameters = {'n_estimators': np.arange(100,1000,180), 'learning_rate':np.arange(0.1, 0.5, 0.1)}\n",
        "cv = KFold(n_splits=5, random_state=142, shuffle=True) \n",
        "gbc = GridSearchCV(gbc, param_grid=parameters, scoring=make_scorer(cv_fpr, greater_is_better = False), cv=cv, verbose=0)\n",
        "gbc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4kbzeX73kg1"
      },
      "outputs": [],
      "source": [
        "gbc_predict_proba = gbc.predict_proba(X_test)[:,1]\n",
        "gbc_predictions = gbc.predict(X_test)\n",
        "gbc.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC0J6r-E-zUf"
      },
      "source": [
        "##Model Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90ZDtm28_M-o"
      },
      "source": [
        "list of relevant variables:\n",
        "\n",
        "model variable names:\n",
        "rfc, gbc, logistic_regression, lasso, ridge, elastic_net, LDA, \n",
        "\n",
        "predict_proba list:\n",
        "rfc_predict_proba, gbc_predict_proba, LDA_predict_proba, logreg_predict_proba, elastic_net_predict_proba, lasso_predict_proba, ridge_predict_proba\n",
        "\n",
        "predictions list:\n",
        "gbc_predictions, LDA_predictions, logreg_predictions, elastic_net_predictions,lasso_predictions, ridge_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJ8HsEHe7EBS"
      },
      "outputs": [],
      "source": [
        "plot_roc(y_test, [rfc_predict_proba, gbc_predict_proba, LDA_predict_proba, logreg_predict_proba, elastic_net_predict_proba, lasso_predict_proba, ridge_predict_proba],\n",
        "         ['Random Forests', 'Gradient Boosting', 'Linear Discriminant Analysis (LDA)', 'Logistic Regression', 'Elastic Net', 'LASSO', 'Ridge'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXQtVJIV_2-o"
      },
      "outputs": [],
      "source": [
        "#Custom class for a voting classifier on our already trained models\n",
        "#sklearn classifier requires unfit models, but we want to use already fit models, so a custom function was needed\n",
        "class ensembler():\n",
        "  def __init__(self, models):\n",
        "    self.models = models\n",
        "  def predict(self, X_test):\n",
        "    predictions = pd.DataFrame()\n",
        "    for i, model in enumerate(self.models):      \n",
        "      predictions[i] = model.predict(X_test)\n",
        "    return predictions.max(axis=1)\n",
        "  def predict_proba(self, X_test):\n",
        "    predictions = pd.DataFrame()\n",
        "    for i, model in enumerate(self.models):      \n",
        "      predictions[i] = model.predict_proba(X_test)[:,1]\n",
        "    return predictions.mean(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brsXqy1MDx6d"
      },
      "outputs": [],
      "source": [
        "ensemble1 = ensembler([rfc, gbc, lasso, LDA])\n",
        "ensemble1_proba = ensemble1.predict_proba(X_test)\n",
        "ensemble1_predictions = ensemble1.predict(X_test)\n",
        "plot_roc(y_test, [ensemble1_proba], ['ensemble of 4 best AUC models'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy_6ijybD33j"
      },
      "outputs": [],
      "source": [
        "validation = pd.concat([pd.DataFrame(X_test), pd.Series(y_test.reset_index()['label'])], axis = 1)\n",
        "valx = validation.drop('label',axis=1)\n",
        "valy = validation['label']\n",
        "rfc_performance = bootstrap_validation(valx, valy, rfc, [get_fpr, get_tpr, get_accuracy, get_AUC], sample=5000, random_state=66)\n",
        "lasso_performance = bootstrap_validation(valx, valy, lasso, [get_fpr, get_tpr, get_accuracy, get_AUC], sample=5000, random_state=66)\n",
        "gbc_performance = bootstrap_validation(valx, valy, gbc, [get_fpr, get_tpr, get_accuracy, get_AUC], sample=5000, random_state=66)\n",
        "LDA_performance = bootstrap_validation(valx, valy, LDA, [get_fpr, get_tpr, get_accuracy, get_AUC], sample=5000, random_state=66)\n",
        "elastic_performance = bootstrap_validation(valx, valy, elastic_net, [get_fpr, get_tpr, get_accuracy, get_AUC], sample=5000, random_state=66)\n",
        "logreg_performance = bootstrap_validation(valx, valy, logistic_regression, [get_fpr, get_tpr, get_accuracy, get_AUC], sample=5000, random_state=66)\n",
        "ridge_performance = bootstrap_validation(valx, valy, ridge, [get_fpr, get_tpr, get_accuracy, get_AUC], sample=5000, random_state=66)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfjAQnvCQYF7"
      },
      "outputs": [],
      "source": [
        "print(f'random forest {calculate_metrics(y_test, rfc_predictions)}')\n",
        "print(f'lasso {calculate_metrics(y_test, lasso_predictions)}')\n",
        "print(f'gradient boosting {calculate_metrics(y_test, gbc_predictions)}')\n",
        "print(f'LDA {calculate_metrics(y_test, LDA_predictions)}')\n",
        "print(f'elastic net {calculate_metrics(y_test, elastic_net_predictions)}')\n",
        "print(f'logistic regression {calculate_metrics(y_test, logreg_predictions)}')\n",
        "print(f'ridge regression {calculate_metrics(y_test, ridge_predictions)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CKkPgbHId1Tq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "LAQnV6BKe8zL",
        "Ev6rnjPR7cmK"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}